% this is a part of the habilitation thesis of Max Neunhoeffer

\chapter{Matrices over finite fields}

This chapter covers the implementation of the basic operations for matrices 
over finite fields. We begin with a description of a new concrete 
representation of such matrices on nowadays computers in 
Section~\ref{sec:ffematrices}, both in main memory and on storage.
We then analyse the performance and complexity of matrix arithmetic 
for this new representation in Section~\ref{sec:matarith} and compare
it to previous implementations. In Section~\ref{sec:basalgmat}, we give
an overview over the most basic algorithms for finite field matrices,
before we conclude this chapter with the description of a new method
to compute minimal polynomials of matrices over finite fields in
Section~\ref{sec:charminpoly}, which is used to compute projective orders
of matrices.

%FIXME

\section{Representing vectors and matrices over finite fields}
\label{sec:ffematrices}

If you already know something about compressed vectors and matrices over 
finite fields you can safely skip the next subsection and directly
proceed to Section~\ref{ssec:cvec}. We first explain the basic idea.

\subsection{The idea}

If $p$ is a prime then elements of the finite field $\F_p$ with $p$
elements can be represented by the integers $0, 1, \ldots, p-1$. Thus,
storing one such element on a computer needs only $\lceil \log_2(p)
\rceil$ bits. The finite extension field  $\F_q$ with $q = p^k$ elements 
is built
as quotient $\F_p[x]/c_k \F_p[x]$ using the Conway polynomial
$c_k$ (see \cite{Nickel} or on the web at \cite{ConwayFL}). Since the
Conway polynomials are monic by definition, an element
of\, $\F_q$ can be represented by one polynomial over\, $\F_p$ of degree 
less then $k$ and thus by storing $k$ elements of\, $\F_p$ using $\lceil
\log_2(p^k) \rceil$ bits.

Since linear algebra operations over finite fields can be performed
rather efficiently by modern microprocessors, the limiting factor 
for such computations is memory access. Therefore, it is performance
critical to store vectors and matrices using as little memory as possible,
and to choose the data structure in a way that allows for fast memory
access. We call such memory efficient data structures ``compressed''.

This idea is quite old (see ADDREFERENCE) and has already been used
extensively (see for example \cite{CMeatAxe} or \cite{GAP4} or
various other systems).

There is a fundamental difference between the characteristic $p=2$ case
and all other characteristics. The reason for this is that in
characteristic $2$ the addition of vectors can be implemented by using
the XOR (exclusive or) operation available in every microprocessor
instruction set. In odd characteristic, the available instructions
do not fit so well to finite field arithmetic. Therefore, previous
implementations mostly rely on table lookups to perform arithmetic
operations. Since the memory space available for lookup tables is
limited, this method is limited to relatively small fields (usually up to
fields with $256$ elements) and has to use single byte accesses
as opposed to processor word accesses, for which modern machines
seem to be optimised. These limitations seem to become more serious
as word lengths in standard microprocessors increase.

The main novelty in the approach presented here is to overcome this
problem by choosing the data structures in a way that allows to use
processor word operations for all arithmetic operations in all
characteristics. Also this idea has been used before (see
\cite{EssenLinAlg}), however, no implementation of this seems to
be available any more and, more importantly, the approach still
insisted on storing whole elements of\, $\F_q$ in one machine word.
We will pack as many prime field elements as possible into a machine
word and distribute the various prime field coefficients of a single
element of\, $\F_q$ into distinct machine words to allow for better
compression of extension field elements.


\subsection{Compressed vectors}
\label{ssec:cvec}

We first describe in detail how a vector of length $n$ over the field
$\F_q$ with $q=p^k$ elements is stored on a machine with word length $32$ 
or $64$ bits respectively. The ideas for the step from $32$ to $64$ bits
can be applied analogously for future microprocessors with even larger
word length. We ignore architectures with funny word lengths not being
a multiple of $32$ bits.

Let $e$ be $\lceil \log_2(2p-1)\rceil$ for $p > 2$ and $1$ for $p=2$. 
This is the number of bits
necessary to store an integer in the range $0,1, \ldots, 2p-2$ except
for $p=2$, where it is $1$. This number $e$ is the number of bits we 
reserve for every prime field element we want to store. For $p=2$ this
is evidently best possible, whereas for odd $p$, we seem to waste
one bit per prime field element, since we seem to need only store
numbers in the range $0,1,\ldots p-1$. This additional bit in the
data structure allows us to represent a sum of two numbers in the
range $0,1,\ldots, p-1$ using $e$ bits in odd characteristic.

We start with the prime field case $q=p$.

We pack as many prime field elements as possible into a machine
word, that is, $w := \lfloor 32/e \rfloor$ prime field elements per word
on a machine with word length $32$ bit. On machines with $64$ bits
we pack $w := 2 \lfloor 32/e \rfloor$ prime field elements into one word.
Note that we do not use $\lfloor 64/e \rfloor$ elements which can be one
more, since then the conversion between the different data formats for
different word lengths becomes too expensive and awkward.

We always imagine the least significant bit in a machine word as being 
on the right hand side. To store a vector, we start filling machine words 
from right to left, always using $e$ bits for one prime field element and
packing $w$ prime field elements into a word.

We illustrate this layout in the following example for $p=5$ and thus
$e=4$ on a machine with $32$ bit word length:

\begin{verbatim}
  bit             3322|2222|2222|1111|1111|1100|0000|0000
  number:         1098|7654|3210|9876|5432|1098|7654|3210
  prime field         |    |    |    |    |    |    |
  element number: 7777|6666|5555|4444|3333|2222|1111|0000
\end{verbatim}

Within each block of $e$ bits, we represent prime field elements
by the binary representation of a number in the range $0,1,\ldots,p-1$
with the least significant bit of this binary representation on the
right hand side. Thus, in our example $1+1+1+1 \in \F_5$ would be
represented by the bit sequence \texttt{0100} and $1+1+1$ by \texttt{0011}.
Note that the most significant bit in this representation is always $0$.

The first $w$ prime field elements in a vector are stored in the first
machine word of the vector, the next $w$ in the next word and so on.

We proceed now to the extension field case $q=p^k$. Let $e$ and $w$ be
exactly the same values as above. We now have to store $k$ prime field
elements for every element of $\F_q = \F_p[x]/c_k\F_p[x]$, namely the 
coefficients of the unique residue class representative of degree smaller 
than $k$, where $c_k$ is the Conway polynomial used to construct the 
finite field extension $\F_q$ over $\F_p$ (for details see \cite{Nickel}
or on the web \cite{ConwayFL}). Namely, if $a \in \F_q$ is represented by
the polynomial $\sum_{i=0}^{k-1} a_i x^i$, then we have to store the prime 
field elements $a_0, a_1, \ldots, a_{k-1}$. 

In a compressed vector of length $n$ of elements of $\F_q$ we distribute
those numbers in the following way: The first $k$ machine words in the
memory representation of the vector are used to store the first $w$
elements of the vector. The first machine word holds all the coefficients
$a_0$ of those $\F_q$ elements, the second the coefficients $a_1$ and so
on. Since one machine word can hold up to $w$ prime field elements this
fills the first $k$ words rather satisfactorily. The second $k$ machine words
in the vector then hold the vector elements with indices 
$w+1, w+2, \ldots, 2w$ in exactly the same way.

Note again that for machines with a word length of $64$ bit we choose the
value $w$ only twice as big as for $32$ bit machines even if one more
prime field element would fit into the machine word.

The only natural limit of this implementation is that 
$\lceil \log_2(2p-1) \rceil$ must be smaller or equal to the word length
of the microprocessor.

We can now explain, how we can add vectors in the above representation
only by doing a series of word operations.

\subsection{Adding compressed vectors}

The basic addition formula for finite field elements is rather simple:
For prime field elements we just have to add two numbers in the range 
from $0$ to $p-1$, and
subtract $p$, if the sum is greater or equal to $p$. The extension
field elements are done component-wise. However, we have to solve
the problem of doing this simple operation using word operations and 
thus doing this for $w$ prime field elements at the same time.
This is easy for $p=2$, since we can use the standard XOR (exclusive or)
operation.

The idea to overcome this problem for $p > 2$ is the following. 
Assume $a$ and $b$
are two integers in the range from $0$ to $p-1$. By adding
$2^{e-1}-p$ to the sum $a+b$ we get $t := a+b+2^{e-1}-p$, which
has the property, that $t \ge 2^{e-1}$ if and only if $a+b \ge p$
(remember $2p-1 \le 2^e$ and thus $p-1 < 2^{e-1}$). That is, if
the number $t$ is represented using binary expansion with $e$ bits,
then the most significant bit is set if and only if $a+b \ge p$.

This idea is now used for two words $a$ and $b$, containing $w$
prime field elements each. Every prime field element uses exactly $e$ bits
in its word and we call these sections of $e$ adjacent bits in a word 
``components'' for the moment. 

We prepare an ``offset'' word $o$ that contains in each component the
number $2^{e-1}-p$ and a ``mask'' word $m$ that contains in each component
the number $2^{e-1}$ meaning, that in each component only the most significant
bit is set and all others are zero. In addition, we keep a word $n$
containing the number $p$ in each component.

The finite field sum $c$ of $a$ and $b$ is now computed in the following way:
First $s := a+b$ and $t := a+b+o$ are computed. We then use an AND 
operation for words to extract exactly the most significant bits of
those components, in which the sum was greater or equal to $p$.
This is done by computing $r := t \ \&\  m$ (we use the \& symbol to
indicate bit-wise AND operations). Bit-shifting
the word $r$ by $e-1$ bits to the right (we use the notation
$r \gg (e-1)$ for this) and subtracting the
result from $r$ now results in a word $u := r - (r \gg (e-1))$
having the number $2^{e-1}-1$
in those components, in which the sum was greater or equal to $p$ and
$0$ in the others. Finally, doing a bitwise AND operation of $u$ with
$n$ results in exactly the right word to subtract from $s$ to get
the correct result.

Thus, the complete formula is
\[ a+b - \Big(\big(r - (r \gg (e-1))\big) \ \&\ n \Big)
   \qquad \mbox{where}\quad r = (a+b+o) \ \&\  m \]

We illustrate this by an example for $p=3$ on a machine with
$32$ bit word length. In this case, $e = 3$ and $w = 10$. We want to
add the words shown below in the rows depicted by \texttt{a} and \texttt{b}.
We also show the prepared words $o$, $m$, and $n$. The bits marked
with \texttt{X} are not used and are all equal to zero.

\begin{verbatim}
  bit             33|222|222|222|211|111|111|110|000|000|000
  number:         10|987|654|321|098|765|432|109|876|543|210
                    |   |   |   |   |   |   |   |   |   |
  a:              XX|000|010|001|000|010|001|000|010|001|000
  b:              XX|000|010|010|010|001|001|001|000|000|000
  o:              XX|001|001|001|001|001|001|001|001|001|001
  m:              XX|100|100|100|100|100|100|100|100|100|100
  n:              XX|011|011|011|011|011|011|011|011|011|011
\end{verbatim}

In the following table we show some intermediate results and repeat
the input values for easier verification:

\begin{verbatim}
  a+b:            XX|000|100|011|010|011|010|001|010|001|000
  a+b+o:          XX|000|101|100|011|100|011|010|011|010|001
  r:              XX|000|100|100|000|100|000|000|000|000|000
  u:              XX|000|011|011|000|011|000|000|000|000|000
  u&n:            XX|000|011|011|000|011|000|000|000|000|000
  result:         XX|000|001|000|010|000|010|001|010|001|000
  a:              XX|000|010|001|000|010|001|000|010|001|000
  b:              XX|000|010|010|010|001|001|001|000|000|000
\end{verbatim}

Of course, it is a coincidence here that $u$ is equal to 
$u \ \&\ n$, since $p = 2^{e-1}-1$.

This means, that the addition of two words containing $w$ prime field
elements can be done in $7$ word operations for $p > 2$. For the
$p=2$ case, we only need one XOR operation. Thus we have proved:

\begin{Prop}[Addition of compressed vectors]
We assume a machine with $32$ bit word length. For $2 < p < 2^{31}$,
two compressed vectors of length $n$ over the field of $q=p^k$
elements can be added using $7k\cdot \lceil n/w \rceil$ word operations
(plus memory fetches and stores), where $w = \lfloor 32/e \rfloor$
and $e = \lceil \log_2(2p-1) \rceil$. 

For $p=2$, only $k \cdot \lceil n/32 \rceil$ word operations are needed.

For machines with $64$ bit word length, the number of word operations
is halved in both cases and we can work with primes $p < 2^{63}$.
\end{Prop}
\Proof See above. \ProofEnd

\begin{Rem}
Assuming a microprocessor
with a long enough instruction pipeline, we can conclude that all this
can be done as fast as accessing the main memory to fetch $a$ and $b$ and
store the result somewhere, such that the number $7$ does not hurt at all. 
For some additional comments on processor
caches see Section~\ref{sec:cache}.
\end{Rem}

Next we consider multiplication of vectors by scalars.

\subsection{Multiplication by scalars}

To explain the method, we restrict our attention to the case that one
compressed vector shall be multiplied by one scalar and the result 
shall be stored in some other memory location.

Let $e$ and $w$ be defined as in Section~\ref{ssec:cvec}.

We start by discussing the prime field case $\F_p$.
Since a scalar $s \in \F_p$ is represented by an integer in the range $0$ 
to $p-1$ in its binary expansion, we can multiply a compressed vector $v$
by $s$ by repeatedly adding vectors to themselves starting with $v$ and
adding up those multiples
whose corresponding bits in the binary expansion of $s$ are set. That is,
if $s = \sum_{i=0}^{e-2} s_i 2^i$ with $s_i \in \{0,1\}$ and again
$e = \lceil \log_2(2p-1) \rceil$, we compute $s\cdot v$ by computing
$v, 2^1 \cdot v, 2^2 \cdot v, \ldots, 2^{e-2} \cdot v$ and then summing
$\sum_{i=0}^{e-2} s_i \cdot (2^i \cdot v)$.
All this can be done with at most $2(e-2)$ vector additions.

We now proceed to the extension field case $\F_q = \F_p[x]/c_k \F_p[x]$ 
with the Conway polynomial $c_k$ and $q = p^k$.
Here again a scalar $s \in \F_q$ is represented by an expansion
$s = \sum_{i=0}^{k-1} s_i x^i + c_k \cdot \F_p[x]$. For the rest of this
section we omit the ``$+ c_k \cdot \F_p[x]$'' and denote cosets
by their representing polynomials of degree less than $k$.

We reduce the problem to scalar multiplications of vectors with
prime field elements. To this end, we have to be able to multiply
a vector with the primitive root $x$.

Considering a single scalar $t = \sum_{i=0}^{k-1} t_i x^i \in \F_q$, 
we see that 
\[ xt = \sum_{i=1}^{k-1} (t_{i-1}x^i) 
+ \sum_{i=0}^{k-1} t_{k-1} \cdot (x^k - c_k) \in \F_q \] 
(remember that we compute in $\F_p[x]$ modulo $c_k$).
Thus, the multiplication by $x$ can be achieved by a shift, one
multiplication of $x^k - c_k$ with the prime field element $t_{k-1}$,
and an addition.

Since we distribute the prime field elements belonging to a single
extension field element in our vector into adjacent words, we can 
do the shift basically for free by accessing a shifted memory location.
But we still have to deal with the fact, that we have $w$ possibly different
highest coefficients $t_{k-1}$ stored together in one word. However,
since we have to multiply all of them with the same prime field element
coming from the expansion of $x^k - c_k = \sum_{i=0}^{k-1} b_i x^i$ 
we can use the method described
for the prime field case above to compute every word to be added to the
shifted vector. That is, for each $k$ adjacent words 
$(a_{jk},a_{jk+1},\ldots,a_{(j+1)k-1})$ in our vector we have to
add the words shifted by one $(0,a_{jk},a_{jk+1},\ldots,a_{(j+1)k-2})$
to the words $(a_{(j+1)k-1} \cdot b_0, \ldots, a_{(j+1)k-1} \cdot b_{i-1})$.
Therefore, the total cost is exactly the same as for one multiplication of
a vector by a prime field scalar and one addition of vectors.

For the full computation of $s \cdot v$, we have to perform this multiplication
by $x$ altogether $k-1$ times, multiply each intermediate result by the
prime field scalar $s_i$ and sum everything up. Thus, the total cost
of the multiplication $s \cdot v$ is the same as $k$ multiplications
of a vector by a prime field scalar and $k-1$ additions of vectors.
Thus, we have proved the following Proposition:

\begin{Prop}[Multiplication of vectors by scalars]
We assume a machine with $32$ bit word length.
Let $p$ be a prime, $q = p^k$, and $w$ and $e$ as above:
$w = \lfloor 32/e \rfloor$ and $e = \lceil \log_2(2p-1) \rceil$.

For $2 < p < 2^{31}$, the total cost of a multiplication of a compressed 
vector $v$ of length $n$ over $\F_q$ by a scalar $s \in \F_p$ is at most 
$14k(e-2)\cdot \lceil 32/w \rceil$ word operations (plus memory fetches
and stores). For $p=2$, the scalar
can only be $0$ or $1$ and therefore no computation is necessary at all.

For $2 < p < 2^{31}$, the total cost of a multiplication of a compressed
vector $v$ of length $n$ over $\F_q$ by a scalar $s \in \F_q$ is at most
$7k^2(2e-3)\cdot \lceil 32/w \rceil$. For $p = 2$, the total cost is
at most $2k(k-1) \cdot \lceil n/32 \rceil$ word operations.
\end{Prop}

\Proof See above and just add up the number of word operations for up
to $k$ multiplications of a vector by a prime field scalar and $k-1$
additions of vectors. Note for $p=2$ that the vector $n$ consists of
$k \cdot \lceil n/32 \rceil$ words and that we have to count one
vector addition for the ``multiplication with a scalar'', since 
the word $a_{(j+1)k-1}$ has to be XORed to those words whose corresponding
bit is set in $x^k - c_k$.
\ProofEnd

% Timings: z := v+w without allocation
% On algol (P4 3GHz)
% Vector F_2, length 100000000, memory 12 500 000 bytes
%  13,8 ms, bedeutet: 25*10^6 B lesen + 12.5*10^6 B schreiben
%                 ==> 1716 MB/s lesen + 858 MB/s schreiben = 2574 MB/s
% Vector F_2, length 1000000, memory 125 000 bytes
%  50,5 ns, bedeutet: 250000 B lesen + 125000 B schreiben
%                 ==> 4720 MB/s lesen + 2360 MB/s schreiben = 7081 MB/s
% Vector F_7, length 25000000, memory 12 500 000 bytes
%  16,0 ms, bedeutet: 25*10^6 B lesen + 12.5*10^6 B schreiben
%                 ==> 1478 MB/s lesen + 739 MB/s schreiben = 2217 MB/s
% Vector F_7, length 250000, memory 125000 bytes
%  52,2 ns, bedeutet: 250000 B lesen + 125000 B schreiben
%                 ==> 4567 MB/s lesen + 2283 MB/s schreiben = 6851 MB/s

\subsection{Memory throughput in real implementations}

\begin{tabular}{|l|r|r|r|r|}
\hline
Test            & cvec, P4 & cvec, Athlon & lib, P4 & lib, Athlon \\
\hline
\hline
$\F_2$, vectors $32\cdot 10^6 b$, $v := v+w$ & 2300 &      &      &      \\
\hline                                                    
$\F_2$, vectors $32\cdot 10^6 b$, $z := v+w$ &      &      & ---  & ---  \\
\hline                                                    
$\F_2$, vectors $125\,000 b$, $v := v+w$     &      &      &      &      \\
\hline                                                    
$\F_2$, vectors $125\,000 b$, $z := v+w$     &      &      & ---  & ---  \\
\hline                                                    
$\F_2$, vectors $62\,500 b$, $v := v+w$      &      &      &      &      \\
\hline                                                    
$\F_2$, vectors $62\,500 b$, $z := v+w$      &      &      & ---  & ---  \\
\hline
\hline
$\F_7$, vectors $32\cdot 10^6 b$, $v := v+w$ & 2300 &      &      &      \\
\hline                                                    
$\F_7$, vectors $32\cdot 10^6 b$, $z := v+w$ &      &      & ---  & ---  \\
\hline                                                    
$\F_7$, vectors $125\,000 b$, $v := v+w$     &      &      &      &      \\
\hline                                                    
$\F_7$, vectors $125\,000 b$, $z := v+w$     &      &      & ---  & ---  \\
\hline                                                    
$\F_7$, vectors $62\,500 b$, $v := v+w$      &      &      &      &      \\
\hline                                                    
$\F_7$, vectors $62\,500 b$, $z := v+w$      &      &      & ---  & ---  \\
\hline
\end{tabular}

\index{Matrix}

\section{Matrix arithmetic}
\label{sec:matarith}

Talk about matrices as lists of vectors and flat matrices.

\subsection{Addition and multiplication with scalars}

\subsection{Vector-matrix multiplication}

\subsection{Matrix multiplication}

Greasing.

\subsection{Matrix inversion}

Greasing.

\subsection{Semi echelonisation}

Cleaning, spinning.

\section{Cache issues}
\label{sec:cache}

Expected performance gain, problems.

\section{Characteristic and minimal polynomial}
\label{sec:charminpoly}

\section{Basic algorithms for matrices}
\label{sec:basalgmat}

Evaluation of polynomials at matrices, order of an invertible matrix.

