% this is a part of the habilitation thesis of Max Neunhoeffer

\chapter{Matrices over finite fields}

This chapter covers the implementation of the basic operations for matrices 
over finite fields. We begin with a description of a new concrete 
representation of such matrices on nowadays computers in 
Section~\ref{sec:ffematrices}, both in main memory and on storage.
We then analyse the performance and complexity of matrix arithmetic 
for this new representation in Section~\ref{sec:matarith} and compare
it to previous implementations. In Section~\ref{sec:basalgmat}, we give
an overview over the most basic algorithms for finite field matrices,
before we conclude this chapter with the description of a new method
to compute minimal polynomials of matrices over finite fields in
Section~\ref{sec:minpoly}, which is used to compute projective orders
of matrices.

\section{Representing matrices over finite fields}
\label{sec:ffematrices}

If you already know something about compressed matrices over finite
fields you can safely skip the next subsection and directly proceed
to Section~\ref{ssec:cvec}. We first explain the basic idea.

\subsection{The idea}

If $p$ is a prime then elements of the finite field $\F_p$ with $p$
elements can be represented by the integers $0, 1, \ldots, p-1$. Thus,
storing one such element on a computer needs only $\lceil \log_2(p)
\rceil$ bits. The finite extension field  $\F_q$ with $q = p^k$ elements 
is built
as quotient $\F_p[x]/c_k \F_p[x]$ using the Conway polynomial
$c_k$ (see \cite{Nickel} or on the web at \cite{ConwayFL}). Since the
Conway polynomials are monic by definition, an element
of\, $\F_q$ can be represented by one polynomial over\, $\F_p$ of degree 
less then $k$ and thus by storing $k$ elements of\, $\F_p$ using $\lceil
\log_2(p^k) \rceil$ bits.

Since linear algebra operations over finite fields can be performed
rather efficiently by modern microprocessors, the limiting factor 
for such computations is memory access. Therefore, it is performance
critical to store vectors and matrices using as little memory as possible,
and to choose the data structure in a way that allows for fast memory
access. We call such memory efficient data structures ``compressed''.

This idea is quite old (see ADDREFERENCE) and has already been used
extensively (see for example \cite{CMeatAxe} or \cite{GAP4} or
various other systems).

There is a fundamental difference between the characteristic $p=2$ case
and all other characteristics. The reason for this is that in
characteristic $2$ the addition of vectors can be implemented by using
the XOR (exclusive or) operation available in every microprocessor
instruction set. In odd characteristic, the available instructions
do not fit so well to finite field arithmetic. Therefore, previous
implementations mostly rely on table lookups to perform arithmetic
operations. Since the memory space available for lookup tables is
limited, this method is limited to relatively small fields (usually up to
fields with $256$ elements) and has to use single byte accesses
as opposed to processor word accesses, for which modern machines
seem to be optimised. These limitations seem to become more serious
as word lengths in standard microprocessors increase.

The main novelty in the approach presented here is to overcome this
problem by choosing the data structures in a way that allows to use
processor word operations for all arithmetic operations in all
characteristics. Also this idea has been used before (see
\cite{EssenLinAlg}), however, no implementation of this seems to
be available any more and, more importantly, the approach still
insisted on storing whole elements of\, $\F_q$ in one machine word.
We will pack as many prime field elements as possible into a machine
word and distribute the various prime field coefficients of a single
element of\, $\F_q$ into distinct machine words to allow for better
compression of extension field elements.


\subsection{Compressed vectors}
\label{ssec:cvec}

We first describe in detail how a vector of length $n$ over the field
$\F_q$ with $q=p^k$ elements is stored on a machine with word length $32$ 
or $64$ bits respectively. The ideas for the step from $32$ to $64$ bits
can be applied analogously for future microprocessors with even larger
word length. We ignore architectures with funny word lengths not being
a multiple of $32$ bits.

Let $e$ be $\lceil \log_2(2p-1)\rceil$ for $p > 2$ and $1$ for $p=2$. 
This is the number of bits
necessary to store an integer in the range $0,1, \ldots, 2p-2$ except
for $p=2$, where it is $1$. This number $e$ is the number of bits we 
reserve for every prime field element we want to store. For $p=2$ this
is evidently best possible, whereas for odd $p$, we seem to waste
one bit per prime field element, since we seem to need only store
numbers in the range $0,1,\ldots p-1$. This additional bit in the
data structure allows us to represent a sum of two numbers in the
range $0,1,\ldots, p-1$ using $e$ bits in odd characteristic.

We start with the prime field case $q=p$.

We pack as many prime field elements as possible into a machine
word, that is, $w := \lfloor 32/e \rfloor$ prime field elements per word
on a machine with word length $32$ bit. On machines with $64$ bits
we pack $w := 2 \lfloor 32/e \rfloor$ prime field elements into one word.
Note that we do not use $\lfloor 64/e \rfloor$ elements which can be one
more, since then the conversion between the different data formats for
different word lengths becomes too expensive and awkward.

We always imagine the least significant bit in a machine word as being 
on the right hand side. To store a vector, we start filling machine words 
from right to left, always using $e$ bits for one prime field element and
packing $w$ prime field elements into a word.

We illustrate this layout in the following example for $p=5$ and thus
$e=4$ on a machine with $32$ bit word length:

\begin{verbatim}
  bit             3322|2222|2222|1111|1111|1100|0000|0000
  number:         1098|7654|3210|9876|5432|1098|7654|3210
  prime field         |    |    |    |    |    |    |
  element number: 7777|6666|5555|4444|3333|2222|1111|0000
\end{verbatim}

Within each block of $e$ bits, we represent prime field elements
by the binary representation of a number in the range $0,1,\ldots,p-1$
with the least significant bit of this binary representation on the
right hand side. Thus, in our example $1+1+1+1 \in \F_5$ would be
represented by the bit sequence \texttt{0100} and $1+1+1$ by \texttt{0011}.
Note that the most significant bit in this representation is always $0$.

The first $w$ prime field elements in a vector are stored in the first
machine word of the vector, the next $w$ in the next word and so on.

We proceed now to the extension field case $q=p^k$. Let $e$ and $w$ be
exactly the same values as above. We now have to store $k$ prime field
elements for every element of $\F_q = \F_p[x]/c_k\F_p[x]$, namely the 
coefficients of the unique residue class representative of degree smaller 
than $k$, where $c_k$ is the Conway polynomial used to construct the 
finite field extension $\F_q$ over $\F_p$ (for details see \cite{Nickel}
or on the web \cite{ConwayFL}). Namely, if $a \in \F_q$ is represented by
the polynomial $\sum_{i=0}^{k-1} a_i x^i$, then we have to store the prime 
field elements $a_0, a_1, \ldots, a_{k-1}$. 

In a compressed vector of length $n$ of elements of $\F_q$ we distribute
those numbers in the following way: The first $k$ machine words in the
memory representation of the vector are used to store the first $w$
elements of the vector. The first machine word holds all the coefficients
$a_0$ of those $\F_q$ elements, the second the coefficients $a_1$ and so
on. Since one machine word can hold up to $w$ prime field elements this
fills the first $k$ words rather satisfactorily. The second $k$ machine words
in the vector then hold the vector elements with indices 
$w+1, w+2, \ldots, 2w$ in exactly the same way.

Note again that for machines with a word length of $64$ bit we choose the
value $w$ only twice as big as for $32$ bit machines even if one more
prime field element would fit into the machine word.

The only natural limit of this implementation is that 
$\lceil \log_2(2p-1) \rceil$ must be smaller or equal to the word length
of the microprocessor.

We can now explain, how we can add vectors in the above representation
only by doing a series of word operations.

\subsection{Adding compressed vectors}

The basic addition formula for finite field elements is rather simple:
For prime field elements we just have to add two numbers in the range 
from $0$ to $p-1$, and
subtract $p$, if the sum is greater or equal to $p$. The extension
field elements are done component-wise. However, we have to solve
the problem of doing this simple operation using word operations and 
thus doing this for $w$ prime field elements at the same time.
This is easy for $p=2$, since we can use the standard XOR (exclusive or)
operation.

The idea to overcome this problem for $p > 2$ is the following. 
Assume $a$ and $b$
are two integers in the range from $0$ to $p-1$. By adding
$2^{e-1}-p$ to the sum $a+b$ we get $t := a+b+2^{e-1}-p$, which
has the property, that $t \ge 2^{e-1}$ if and only if $a+b \ge p$
(remember $2p-1 \le 2^e$ and thus $p-1 < 2^{e-1}$). That is, if
the number $t$ is represented using binary expansion with $e$ bits,
then the most significant bit is set if and only if $a+b \ge p$.

This idea is now used for two words $a$ and $b$, containing $w$
prime field elements each. Every prime field element uses exactly $e$ bits
in its word and we call these sections of $e$ adjacent bits in a word 
``components'' for the moment. 

We prepare an ``offset'' word $o$ that contains in each component the
number $2^{e-1}-p$ and a ``mask'' word $m$ that contains in each component
the number $2^{e-1}$ meaning, that in each component only the most significant
bit is set and all others are zero. In addition, we keep a word $n$
containing the number $p$ in each component.

The finite field sum $c$ of $a$ and $b$ is now computed in the following way:
First $s := a+b$ and $t := a+b+o$ are computed. We then use an AND 
operation for words to extract exactly the most significant bits of
those components, in which the sum was greater or equal to $p$.
This is done by computing $r := t \ \&\  m$ (we use the \& symbol to
indicate bit-wise AND operations). Bit-shifting
the word $r$ by $e-1$ bits to the right (we use the notation
$r \gg (e-1)$ for this) and subtracting the
result from $r$ now results in a word $u := r - (r \gg (e-1))$
having the number $2^{e-1}-1$
in those components, in which the sum was greater or equal to $p$ and
$0$ in the others. Finally, doing a bitwise AND operation of $u$ with
$n$ results in exactly the right word to subtract from $s$ to get
the correct result.

Thus, the complete formula is
\[ a+b - \Big(\big(r - (r \gg (e-1))\big) \ \&\ n \Big)
   \qquad \mbox{where}\quad r = (a+b+o) \ \&\  m \]

We illustrate this by an example for $p=3$ on a machine with
$32$ bit word length. In this case, $e = 3$ and $w = 10$. We want to
add the words shown below in the rows depicted by \texttt{a} and \texttt{b}.
We also show the prepared words $o$, $m$, and $n$. The bits marked
with \texttt{X} are not used and are all equal to zero.

\begin{verbatim}
  bit             33|222|222|222|211|111|111|110|000|000|000
  number:         10|987|654|321|098|765|432|109|876|543|210
                    |   |   |   |   |   |   |   |   |   |
  a:              XX|000|010|001|000|010|001|000|010|001|000
  b:              XX|000|010|010|010|001|001|001|000|000|000
  o:              XX|001|001|001|001|001|001|001|001|001|001
  m:              XX|100|100|100|100|100|100|100|100|100|100
  n:              XX|011|011|011|011|011|011|011|011|011|011
\end{verbatim}

In the following table we show some intermediate results:

\begin{verbatim}
  a+b:            XX|000|100|011|010|011|010|001|010|001|000
  a+b+o:          XX|000|101|100|011|100|011|010|011|010|001
  r:              XX|000|100|100|000|100|000|000|000|000|000
  u:              XX|000|011|011|000|011|000|000|000|000|000
  u&n:            XX|000|011|011|000|011|000|000|000|000|000
  result:         XX|000|001|000|010|000|010|001|010|001|000
\end{verbatim}

Of course, it is a coincidence here that $u$ is equal to 
$u \ \&\ n$, since $p = 2^{e-1}-1$.

This means, that the addition of two words containing $w$ prime field
elements can be done in $7$ word operations for $p > 2$. For the
$p=2$ case, we only need one exclusive OR operation. Assuming a microprocessor
with a long enough instruction pipeline, we can conclude that all this
can be done as fast as accessing the main memory to fetch $a$ and $b$ and
store the result somewhere. For some additional comments on processor
caches see Section~\ref{sec:cache}.

Next we consider multiplication of vectors by scalars.

\subsection{Multiplication by scalars}


\index{Matrix}

\section{Matrix arithmetic}
\label{sec:matarith}

\section{Cache issues}
\label{sec:cache}

\section{Basic algorithms for matrices}
\label{sec:basalgmat}

\section{Computing minimal polynomials}
\label{sec:minpoly}

