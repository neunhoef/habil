% is is a part of the habilitation thesis of Max Neunhoeffer

\chapter{Further linear algebra algorithms}
\label{chap:linalg}

In this chapter we collect for the sake of completeness some
linear algebra algorithms together with their complexity analysis
that are used in later chapters. At the end we comment on two major
open problems, namely the discrete logarithm problem in finite fields and
integer factorisation, which come up in the analysis of matrix group
algorithms.

\section{Order and projective order of a matrix}
\label{sec:orders}

This section is about the computation of the order and the projective
order of a matrix $M \in \F_q^{n \times n}$. After defining these 
terms we describe the 
ideas of the method in \cite{CellLeedOrder} in particular to show
two things: First that computing the minimal polynomial of a matrix
\index{minimal polynomial}%
is a crucial step in the computation of its order, and second that
integer factorisations of some of the numbers $q^i-1$ for $1 \le i \le n$ 
can be needed in the process (see Section~\ref{intfact}).

\begin{DefProp}[Order and projective order]
\index{order of a matrix}\index{projective order of a matrix}%
Let $\F$ be a field and $M \in \F^{n \times
n}$ an invertible matrix. The \emph{order} of $M$ is the least natural
number $o$ such that $M^o$ is equal to the identity matrix\/ $\one$.
The \emph{projective order} of $M$ is the least natural number $p$
such that $M^p$ is a scalar matrix, that is, a scalar multiple of the
identity matrix. It follows immediately by division with remainder in
the exponent that $o$ divides every natural number $k$ for which 
$M^k$ is equal to\/ $\one$ and that $p$ divides every natural number $k$
for which $M^k$ is a scalar multiple of\/ $\one$. Thus $p$ divides in
particular $o$ and it follows immediately that, if $M^p = \lambda \cdot
\one$ with $\lambda \in \F$, then $o$ is $p$ times the order of the
scalar $\lambda$. \proofend
\end{DefProp}

For a monic polynomial $f \in \F[X]$ with non-zero constant term
we define the \emph{order} (\emph{projective order} respectively) of 
$X + f\F[X]$ in $\F[X]/f\F[X]$ modulo $f$ as the least natural 
number $p$ such that $X^p$ is congruent 
to $1$ (a scalar respectively) modulo $f$ or equivalently, that $X^p-1$ 
($X^p-\lambda$ respectively) is
divisible by $f$ (for some $\lambda \in \F$). 
The order and projective order
of a matrix $M$ as above and that of $X$ modulo the minimal polynomial 
of $M$ are linked by the following lemma.

\enlargethispage{1\baselineskip}
\begin{Lemm}[Orders and projective orders]
Let\/ $\F$ be a field and $M \in \F^{n \times n}$ an invertible matrix.
Then the (projective) order of $M$ is equal to the (projective) order of
$X + \mu_M \F[X]$ modulo the minimal polynomial $\mu_M$ of $M$.
\end{Lemm}
\proofbeg 
The polynomial $X^p-\lambda$ is divisible by $\mu_M$ if and
only if $M^p = \lambda \one$ for all $\lambda \in \F$.
\proofend

In the following we use this lemma to switch between matrices and
polynomials as seems appropriate for the argumentation.

Now we want to discuss the computation of both the order and the
projective order of a matrix or its minimal polynomial respectively.

Let $f \in \F[X]$ be a monic polynomial with non-zero constant term. 
By the Chinese Remainder theorem the factor ring
$\F[X]/f\F[X]$ is isomorphic to
\[ \F[X]/f\F[X] \cong
   \prod_{i=1}^k \F[X]/f_i^{e_i} \F[X] \]
where $f = \prod_{i=1}^k f_i^{e_i}$ is the factorisation of $f$ into
its pairwise distinct irreducible factors $f_i$. Using this
isomorphism the (projective) order of $X+f\F[X]$ is equal to the least 
common multiple of the (projective) orders of the $X + f_i^{e_i}
\F[X]$ in $\F[X]/f_i^{e_i}\F[X]$. Thus, as a first step we factorise
$f$ completely and now determine the (projective) order of
$X+g^e\F[X]$ for an irreducible monic polynomial $g$ of degree $d$ 
with non-zero constant term.

From now on we switch back to matrices. Let $C \in \F^{d \times d}$ be 
the companion matrix of $g$ and $N$ the $(de \times de)$-block matrix with 
$C$ along the main block diagonal, $(d \times d)$-identity matrices
along the block diagonal directly above the main diagonal and zero blocks
elsewhere:
\[ N = \left[ \begin{array}{ccccc}
    C      & \one   & 0      & \cdots & 0 \\
    0      & C      & \one   & \ddots & \vdots \\
    \vdots & \ddots & \ddots & \ddots & 0 \\
    \vdots & \ddots & \ddots & C      & \one \\
    0      & \cdots & \cdots & 0      & C
\end{array} \right]. \]
The minimal polynomial $\mu_N$ of $N$ over $\F$ is $g^e$ 
which can be seen as follows:
Let $K$ be the splitting field $K$ of $g$ over $\F$. Since $g$ is
irreducible and thus has no multiple roots, the 
matrix $C$ is similar to a diagonal matrix over $K$, that is, there is an
invertible $T \in K^{d \times d}$ such that $TCT^{-1}$ is diagonal
with pairwise disjoint eigenvalues.
Thus, conjugating $N$ with the block matrix having $T$ along the
main block diagonal and permuting rows and columns suitably shows that
the Jordan normal form of $N$ over $K$ consists of $d$ blocks of
size $e$, thus every eigenvalue of $C$ occurs in the minimal
polynomial of $N$ with multiplicity $e$. Thus the minimal polynomial
of $N$ over $K$ is $g^e$ and thus also $\mu_N = g^e$.

We assume from now on that $\F$ is the finite field $\F_q$ with $q$
elements.
Writing $N = \tilde C + \tilde \one$ where $\tilde C$ is the matrix
with only $C$ along the main block diagonal and $\tilde \one$
accordingly we have $\tilde C \cdot \tilde \one = \tilde \one \cdot \tilde C$
and thus $N^k = \sum_{i=0}^k {k \choose i} \tilde C^{k-i} \tilde
\one^i$. This immediately implies that the $(d \times d)$-block
of $N^k$ in position $(j,j+i)$ is ${k \choose i}C^{k-i}$ for all
$1 \le j \le d-i$. 

Therefore the (projective) order of $N$ can be determined in the
following way: The number $\lceil \log_p(e)\rceil$ is the number
of factors $p$ that have to occur in $k$, such that all binomial
coefficients ${k \choose i} \equiv 0 \ (\mbox{mod } p)$ for $1 \le i < e$ 
(where we set ${k
\choose i} = 0$ for $i > k$). Let $l$ be the (projective) order of
$X+g\F[X]$ in the field $\F[X]/g\F[X]$. Then the (projective) order of
$N$ is the product $p^{\lceil \log_p(e) \rceil} \cdot l$. Note that
determining the number $l$ involves computing in the field extension
$\F[X]/g\F[X]$.

In practice one takes $q^d-1$ (respectively $\frac{q^d-1}{q-1}$) 
as an upper bound
for the (projective) order of $X+g\F[X]$ and then uses the ``bounded order
algorithm'' described in \cite[Section 2]{CellLeedOrder} to get the
actual (projective) order. However, this algorithm depends on the
integer factorisation (see Section~\ref{intfact}) 
of $q^d-1$ since it uses a divide-and-conquer
approach using this factorisation.

Altogether we can conclude the following result.

\begin{Prop}[Computing the (projective) order of a matrix]
\index{order of a matrix}\index{projective order of a matrix}%
Let $M$ be a matrix in\/ $\F_q^{n \times n}$. Assume that the 
minimal polynomial of $M$ is known and completely factorised into
\index{minimal polynomial}%
irreducible factors, and that all integer factorisations of $q^i-1$
for $1 \le i \le n$ are known (see Section~\ref{intfact}). 

Then the (projective) order of $M$ can be
computed in $O(n^3 \cdot \log_2(q) \cdot \log_2(n\log_2(q)))$
field operations.
\end{Prop}
\proofbeg Use the same arguments as in the proof of 
\cite[\textsc{Order Algorithm}]{CellLeedOrder}. 
\proofend

\begin{Rem}
This shows that every improvement of the algorithm to compute the
minimal polynomial also helps to compute the (projective) order.
\index{minimal polynomial}%
\end{Rem}

\section{Solving systems of linear equations}
\label{sec:syslineq}
\index{system of linear equations}%

This section describes and analyses the problem of solving a system
of linear equations. This can be formulated as follows:

Let $\F$ be a field, $Y \in \F^{m \times n}$ and $b \in \F^{1 \times n}$.
Find all $x \in \F^{1 \times m}$ with $xY = b$.

Sometimes the problem has to be solved for more than one $b$ and sometimes
it is enough to find one solution $x$. In particular the homogeneous case 
$b=0$ is important, here the set of solutions is called the \emph{nullspace}
of $M$.
\index{nullspace}%

The general approach to this problem is standard, thus we are mostly
interested in the complexity. The basic procedure is
Algorithm~\ref{semiechelonise}: By running
all rows of $Y$ successively through Algorithm~\ref{clean} we
find three things in the process: First a subsequence
$t=(t_1,t_2, \ldots, t_{r})$ of $(1,2,\ldots, m)$ with
$1 \le t_1 < t_2 < \cdots < t_r \le m$ such that the matrix
$Y' \in \F^{r \times n}$ consisting of the rows with numbers 
$t_1, t_2, \ldots, t_r$ of $Y$ has rank $r$. Secondly we get a
semi echelon data sequence $\calY = (Y',S,T,l)$ for $Y'$ as defined
in Definition~\ref{semiecheseq}. Thirdly, for every row of $Y$ that
is a linear combination of the rows above it in $Y$, we find a linear 
relation of the rows of $Y$ and all these relations span the nullspace
of $Y$ in the end.

We leave the details and the proof that this procedure does what
we claim to the reader. The following proposition analyses the cost
of Algorithm~\ref{semiechelonise}.

\begin{algorithm}
\caption{$\quad$ \sc SemiEchelonise}
\index{SemiEchelonise@\textsc{SemiEchelonise}}%
\label{semiechelonise}
\begin{algorithmic}
\STATE \textbf{Input:} A matrix $Y \in \F^{m \times n}$.
\STATE \textbf{Output:} Indices $1 \le t_1 < t_2 < \cdots < t_r$,
a matrix $Y' \in \F^{r \times n}$ with semi echelon data sequence
\STATE \mbox{}\phantom{\textbf{Output:}}
$\calY = (Y',S,T,l)$ and a matrix $N \in \F^{(m-r) \times n}$
whose rows span the nullspace of $Y$
\STATE $\calY := $ empty semi echelon sequence for rows with length $n$
\STATE $N := $ empty matrix for rows with length $n$
\STATE $t := $ empty sequence
\FOR {$i=1$ to $m$}
    \STATE $(f,\calY,a) := \textsc{CleanAndExtend}(\calY,Y[i])$
    \IF {$f = \textsc{True}$}
        \STATE Append a row to $N$ using $a$
    \ELSE
        \STATE Append $i$ to sequence $t$
    \ENDIF
\ENDFOR
\STATE \textbf{Return:} $(t,\calY,N)$
\end{algorithmic}
\end{algorithm}

\begin{Prop}[Complexity of Algorithm~\ref{semiechelonise}]
\label{semiechelon}
\index{SemiEchelonise@\textsc{SemiEchelonise}}%
If $r$ is the rank of $M$, Algorithm~\ref{semiechelonise} needs
at most
\[ \frac{r(r+1)(2r+1)}{6} + nr^2 + 2rn(m-r) + r \]
elementary field operations. This is $O(nm^2)$.
\end{Prop}
\proofbeg
We add up the maximal number of elementary field operations needed
by the calls to \textsc{CleanAndExtend} using
Proposition~\ref{PropCleanAndExtend}. We start with the calls that
extend the semi echelon data sequence:
\begin{eqnarray*}
\sum_{i=0}^{r-1} \left( (2i+1)n + (i+1)^2 + 1 \right) 
  &=& \frac{r(r-1)}{2} \cdot 2n + rn + \frac{r(r+1)(2r+1)}{6} + r \\
  &=& nr^2 + \frac{r(r+1)(2r+1)}{6} + r,
\end{eqnarray*}
where we use Formulas \ref{formels1} and \ref{formels2}. In the worst
case that the first $r$ rows of $Y$ are linearly independent the
number of operations used to clean the rows that do not extend
the semi echelon data sequence is at most $(m-r)\cdot 2rn$.
For the asymptotic statement we use $r \le \min\{ m,n \}$.
\proofend

\medskip
After Algorithm~\ref{semiechelonise} has completed, the rows of the
matrix $N$ span the solution space of the system of linear equations
$xY = 0$. For a given $0 \neq b \in \F^{1 \times n}$ we have to run
the ``cleaning'' part of Algorithm~\ref{clean} once.
The result is either that the system has no solutions or a vector
$a \in \F^{1 \times r}$ such that $b = aS = aTY'$ for the matrix $S$ in
$\calY$ that is in row semi echelon form. Since $Y'$ consists of a 
selection of the rows of $Y$, the vector $aT$ contains all the necessary
information to put together a solution $x$ with $b = xY$. The set
of all solutions is then equal to $\{ x+n \mid n \in \rsp(N) \}$.

\enlargethispage{-1\baselineskip}
\begin{Cor}[Solving a system of linear equations]
\label{solvelinsys}
\index{system of linear equations}%
The set of solutions of the system of linear equations $xY=0$ can be
read off from the output of Algorithm~\ref{semiechelonise}. For
the system $xY=b$ it can be derived using
$2rn + r(r+1)$ elementary field operations.

Thus such a system can be solved in $O(nm^2)$ elementary field operations.
\end{Cor}
\proofbeg
The above method needs one call to \textsc{CleanAndExtend} using at most
$2rn$ elementary field operations and the vector matrix multiplication
$aT$ with the lower triangular matrix $T$ needs at most
$2\cdot \frac{r(r+1)}{2}$ elementary field operations.
\proofend

\section{Inverting matrices}
\label{sec:invert}
\index{inverting a matrix}%

Inverting a matrix $M \in \F^{n \times n}$ is the same as solving the
system of linear equations $xM = e_i$ for all the standard basis
vectors $e_i \in \F^{1 \times n}$. By Proposition~\ref{semiechelon}
and Corollary~\ref{solvelinsys} we get the following result.

\begin{Prop}[Inverting a matrix]
\index{inverting a matrix}%
Let $M \in \F^{n \times n}$ be an invertible matrix. Then the inverse
can be computed using at most
\[ \frac{n(n+1)(2n+1)}{6} + 4n^3 + n^2 + n \]
elementary field operations, which is asymptotically less than $5n^3$
and this is $O(n^3)$.
\end{Prop}
\proofbeg
We first run Algorithm~\ref{semiechelonise} using at most
\[ \frac{n(n+1)(2n+1)}{6} + n^3 + n \]
elementary field operations by Proposition~\ref{semiechelon}. Then
we solve $xM = e_i$ for $1 \le i \le n$ using a total of
\[ n(2n^2+n(n+1)) = 3n^3+n^2 \]
elementary field operations. Summing up gives the claim.
\proofend

\section{The discrete logarithm problem}
\label{thedlp}
\index{discrete logarith problem}\index{DLP}%

\begin{Problem}[The discrete logarithm problem in finite fields]
\index{discrete logarith problem}\index{DLP}%
    Let $q = p^k$ be a power of a prime $p$. Then the multiplicative
    group of the finite field $\F_q$ is cyclic, say $\F_q^\times =
    \left< \zeta \right>$ for a fixed element $\zeta$ of order $q-1$.

    The discrete logarithm problem (DLP) in the finite field $\F_q$ is
    the following:

    \begin{center}\fbox{\parbox{3.5in}{\hfill
    Given $y \in \F_q^\times$, find $a \in \Z$ such that $y =
    \zeta^a$.\hfill\mbox{}}}
\end{center}
\end{Problem}

\subsection*{Computing discrete logarithms}
\index{discrete logarith problem}\index{DLP}%

Obviously this problem can be solved easily using an algorithm that
simply tries all powers of~$\zeta$. However, this simplistic approach
has complexity $O(q)$ in the worst case, which very quickly
becomes impractical as $q$ grows.

Better methods are the Shanks and Pollard methods (see 
\index{Shanks method}\index{Pollard method}%
\cite[Section~3]{odlyzkodlp}) with complexity $O(q^{1/2})$, 
the Index Calculus Method due to
\index{Index Calculus Method}%
Kraitchik (see \cite{McCurley}) and the more recent Number Field Sieve
methods (see \cite[Section~4]{odlyzkodlp}).
\index{Number Field Sieve}%

An overview of the current state of the art to solve this problem
including lots of references
is given in \cite{odlyzkodlp}. For some values of $q$ (in particular
for ``small $p$'') there are known
algorithms with an asymptotic complexity of
\[ \exp( (C+o(1)) (\log q)^{1/3} (\log \log q)^{2/3} ) \]
for some constant $C$,
but it is still an active area of research to come up with methods
with this complexity for all values of $q$.

Currently there seems to be no hope for algorithms that have
polynomial complexity in $\log q$ on classical computers. The development
of quantum computers might change this in the future.

For practical purposes in matrix group algorithms 
we can safely assume that the discrete logarithm
problem does not pose any significant difficulties as long as $q$ is
smaller or equal to $2^{32}$.
\index{discrete logarith problem}\index{DLP}%

\section{Integer factorisation}
\label{intfact}
\index{integer factorisation}%

\begin{Problem}[The integer factorisation problem]
\index{integer factorisation}%
    Let $n \in \N$ be an integer.
    The integer factorisation problem is the following:

    \begin{center}\fbox{\parbox{5in}{\hfill
        Find the unique expression of $n$ as a product of prime
        powers $n = \prod_{i=1}^k p_i^{e_i}$. 
        \hfill\mbox{}}}
\end{center}
\end{Problem}

\subsection*{Computing integer factorisations}
\index{integer factorisation}%

Obviously this problem can be solved by trial division in time
$O(n^{1/2} \log^2 n)$, however, like for the discrete logarithm problem, 
there is currently no known
algorithm to solve this problem with complexity that is polynomial
in $\log n$.

An overview of the current state of the art in integer factorisation
is given in \cite{gabifaktorisierung}.

For numbers $n$ of the special form $a^k \pm 1$, which includes the
cardinalities $p^k - 1$ of the multiplicative groups of finite fields,
extensive tables for ``small'' values of $a$ and $k$ have been
collected. They can be found on the site \cite{brentfact} and are
built into computer algebra systems to speed up integer factorisation.
In particular the factorisations of all numbers $a^k \pm 1$ which are
smaller than $10^{255}$ are provided there.

For practical purposes in matrix group algorithms 
we can safely assume that the integer factorisation
problem for $n = q^i - 1$ 
does not pose any significant difficulties as long as $q^i$ is
smaller than $10^{255}$.
\index{integer factorisation}%


